{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97c6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis\n",
    "# DDXPlus (10 types, each 40q; total 400q)\n",
    "# top 1 reference + 1 llmself generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ad284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Env setup (deepseek)\n",
    "import getpass\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "#os.environ[\"OPENAI_BASE_URL\"] = os.getenv('OPENAI_BASE_URL')\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = os.getenv('DEEPSEEK_API_KEY')\n",
    "os.environ[\"DEEPSEEK_BASE_URL\"] = os.getenv('DEEPSEEK_BASE_URL')\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# CSV env\n",
    "import sys\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(r'C:\\Users\\Sin Yee\\Desktop\\rag_techniques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf0cdbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sin Yee\\AppData\\Local\\Temp\\ipykernel_22648\\2468998297.py:30: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)\n"
     ]
    }
   ],
   "source": [
    "## Verifier & Summarizer Func (MCQ)\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "## Verifier Agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "verifier_prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\", \n",
    "        \"You are a medical verifier AI.\\n\"\n",
    "        \"Your role is to evaluate whether each reference is **relevant to the symptoms** described in the original question.\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"1. Carefully read the symptom description in the question.\\n\"\n",
    "        \"2. For each agent's reference, check if it describes symptoms that match or strongly relate to the question.\\n\"\n",
    "        \"3. Do NOT exclude a reference just because it refers to a different disease — as long as the symptoms are relevant, it should be kept.\\n\"\n",
    "        \"4. Exclude any references that do not meaningfully align with the symptom description, even if they are medically valid.\\n\"\n",
    "        \"5. Focus only on symptom relevance — diagnosis accuracy will be handled separately.\\n\\n\"\n",
    "        \"Output format:\\n\"\n",
    "        \"'selected_agents': [list of agent names with relevant references — do not modify the names]\\n\\n\"\n",
    "        \"DO NOT respond with anything else — no reasoning, no explanations, no formatting changes.\"\n",
    "    ),\n",
    "    (\"human\", \n",
    "     \"Original Question:\\n{question}\\n\\n\"\n",
    "     \"Retrieved Reference:\\n{ref}\")\n",
    "])\n",
    "\n",
    "\n",
    "verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)\n",
    "\n",
    "def verifier_agent(question: str, agent_reference: str):\n",
    "    verifier_result = verifier_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"ref\": agent_reference\n",
    "    })\n",
    "    print(f\"[Verifier response]:{verifier_result['text']}\")\n",
    "    \n",
    "    return verifier_result['text']\n",
    "\n",
    "## Summarizer Agent (MCQ)\n",
    "from typing import Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def summarizer_agent(verified_references: Dict[str, Dict[str, str]], query: str) -> Dict[str, Any]:\n",
    "    # Step 1: Extract all reference text across all sub-questions and sources\n",
    "    flattened_refs = []\n",
    "    for subq, sources in verified_references.items():\n",
    "        for source_name, content in sources.items():\n",
    "            flattened_refs.append(f\"[{source_name}] {content}\")\n",
    "\n",
    "    # Step 2: Combine all references into a block\n",
    "    context_block = \"\\n\\n\".join(flattened_refs)\n",
    "\n",
    "    options = \"Anemia, Boerhaave, Cluster headache, GERD, Influenza, Myocarditis, Panic attack, Pericarditis, Pneumonia, Sarcoidosis\"\n",
    "\n",
    "    # Step 3: Prepare the prompt\n",
    "    user_prompt = (\n",
    "        f\"You are a Medical QnA AI. Use the references as contexts to answer the question.\\n\\n\"\n",
    "        f\"MUST Answer with your own knowledge, if the references are irrelevant or wrong.\\n\\n\"\n",
    "        f\"Select the single most likely diagnosis from the options.\\n\\n\"\n",
    "        f\"Respond ONLY with the disease name.\\n\\n\"\n",
    "        f\"Do NOT include reference labels in your answer.\\n\\n\"\n",
    "        f\"### References:\\n{context_block}\\n\\n\"\n",
    "        f\"### Question:\\n{query}\\n\\n\"\n",
    "        f\"### Options:\\n{options}\\n\\n\"\n",
    "        f\"### Final Answer:\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Compose messages and call LLM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Medical QnA AI that selects the most accurate answer.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Step 5: Return final result\n",
    "    return {\n",
    "        \"final_answer\": response.content.strip(),\n",
    "        \"references\": verified_references\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (deepseek)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/ddxplus_400_results.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"EVIDENCES\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"ds_reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references, ensure_ascii=False) # convert dict to string\n",
    "            df.loc[i, \"ds_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"ds\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/ddxplus_400_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab53fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Env setup (gpt-4o-mini)\n",
    "import getpass\n",
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "#os.environ[\"OPENAI_BASE_URL\"] = os.getenv('OPENAI_BASE_URL')\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# CSV env\n",
    "import sys\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from pathlib import Path\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(r'C:\\Users\\Sin Yee\\Desktop\\rag_techniques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier & Summarizer Func (MCQ)\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "## Verifier Agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "verifier_prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\", \n",
    "        \"You are a medical verifier AI.\\n\"\n",
    "        \"Your role is to evaluate whether each reference is **relevant to the symptoms** described in the original question.\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"1. Carefully read the symptom description in the question.\\n\"\n",
    "        \"2. For each agent's reference, check if it describes symptoms that match or strongly relate to the question.\\n\"\n",
    "        \"3. Do NOT exclude a reference just because it refers to a different disease — as long as the symptoms are relevant, it should be kept.\\n\"\n",
    "        \"4. Exclude any references that do not meaningfully align with the symptom description, even if they are medically valid.\\n\"\n",
    "        \"5. Focus only on symptom relevance — diagnosis accuracy will be handled separately.\\n\\n\"\n",
    "        \"Output format:\\n\"\n",
    "        \"'selected_agents': [list of agent names with relevant references — do not modify the names]\\n\\n\"\n",
    "        \"DO NOT respond with anything else — no reasoning, no explanations, no formatting changes.\"\n",
    "    ),\n",
    "    (\"human\", \n",
    "     \"Original Question:\\n{question}\\n\\n\"\n",
    "     \"Retrieved Reference:\\n{ref}\")\n",
    "])\n",
    "\n",
    "\n",
    "verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)\n",
    "\n",
    "def verifier_agent(question: str, agent_reference: str):\n",
    "    verifier_result = verifier_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"ref\": agent_reference\n",
    "    })\n",
    "    print(f\"[Verifier response]:{verifier_result['text']}\")\n",
    "    \n",
    "    return verifier_result['text']\n",
    "\n",
    "## Summarizer Agent (MCQ)\n",
    "from typing import Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def summarizer_agent(verified_references: Dict[str, Dict[str, str]], query: str) -> Dict[str, Any]:\n",
    "    # Step 1: Extract all reference text across all sub-questions and sources\n",
    "    flattened_refs = []\n",
    "    for subq, sources in verified_references.items():\n",
    "        for source_name, content in sources.items():\n",
    "            flattened_refs.append(f\"[{source_name}] {content}\")\n",
    "\n",
    "    # Step 2: Combine all references into a block\n",
    "    context_block = \"\\n\\n\".join(flattened_refs)\n",
    "\n",
    "    options = \"Anemia, Boerhaave, Cluster headache, GERD, Influenza, Myocarditis, Panic attack, Pericarditis, Pneumonia, Sarcoidosis\"\n",
    "\n",
    "    # Step 3: Prepare the prompt\n",
    "    user_prompt = (\n",
    "        f\"You are a Medical QnA AI. Use the references as contexts to answer the question.\\n\\n\"\n",
    "        f\"Answer with your internal knowledge, if the references are irrelevant or wrong.\\n\\n\"\n",
    "        f\"Select the single most likely diagnosis from the options.\\n\\n\"\n",
    "        f\"Respond ONLY with the disease name.\\n\\n\"\n",
    "        f\"Do NOT include reference labels in your answer.\\n\\n\"\n",
    "        f\"### References:\\n{context_block}\\n\\n\"\n",
    "        f\"### Question:\\n{query}\\n\\n\"\n",
    "        f\"### Options:\\n{options}\\n\\n\"\n",
    "        f\"### Final Answer:\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Compose messages and call LLM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Medical QnA AI that selects the most accurate answer.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Step 5: Return final result\n",
    "    return {\n",
    "        \"final_answer\": response.content.strip(),\n",
    "        \"references\": verified_references\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67426b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (gpt)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/ddxplus_400_results.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"EVIDENCES\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"gpt_reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references, ensure_ascii=False) # convert dict to string\n",
    "            df.loc[i, \"gpt_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"gpt\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/ddxplus_400_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis\n",
    "# SymptomsDisease (10 types; 486q)\n",
    "# top 5 references\n",
    "# https://huggingface.co/datasets/sajjadhadi/disease-diagnosis-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier & Summarizer Func (MCQ)\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "## Verifier Agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "verifier_prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\", \n",
    "        \"You are a medical verifier AI.\\n\"\n",
    "        \"Your role is to evaluate whether each reference is **relevant to the symptoms** described in the original question.\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"1. Carefully read the symptom description in the question.\\n\"\n",
    "        \"2. For each agent's reference, check if it describes symptoms that match or strongly relate to the question.\\n\"\n",
    "        \"3. Do NOT exclude a reference just because it refers to a different disease — as long as the symptoms are relevant, it should be kept.\\n\"\n",
    "        \"4. Exclude any references that do not meaningfully align with the symptom description, even if they are medically valid.\\n\"\n",
    "        \"5. Focus only on symptom relevance — diagnosis accuracy will be handled separately.\\n\\n\"\n",
    "        \"Output format:\\n\"\n",
    "        \"'selected_agents': [list of agent names with relevant references — do not modify the names]\\n\\n\"\n",
    "        \"DO NOT respond with anything else — no reasoning, no explanations, no formatting changes.\"\n",
    "    ),\n",
    "    (\"human\", \n",
    "     \"Original Question:\\n{question}\\n\\n\"\n",
    "     \"Retrieved Reference:\\n{ref}\")\n",
    "])\n",
    "\n",
    "\n",
    "verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)\n",
    "\n",
    "def verifier_agent(question: str, agent_reference: str):\n",
    "    verifier_result = verifier_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"ref\": agent_reference\n",
    "    })\n",
    "    print(f\"[Verifier response]:{verifier_result['text']}\")\n",
    "    \n",
    "    return verifier_result['text']\n",
    "\n",
    "## Summarizer Agent (MCQ)\n",
    "from typing import Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def summarizer_agent(verified_references: Dict[str, Dict[str, str]], query: str) -> Dict[str, Any]:\n",
    "    # Step 1: Extract all reference text across all sub-questions and sources\n",
    "    flattened_refs = []\n",
    "    for subq, sources in verified_references.items():\n",
    "        for source_name, content in sources.items():\n",
    "            flattened_refs.append(f\"[{source_name}] {content}\")\n",
    "\n",
    "    # Step 2: Combine all references into a block\n",
    "    context_block = \"\\n\\n\".join(flattened_refs)\n",
    "\n",
    "    options = \"anemia, allergy, fibromyalgia, gastroesophageal reflux disease (gerd), gout, heart failure, rheumatoid arthritis, spondylosis, schizophrenia, thrombophlebitis\"\n",
    "\n",
    "    # Step 3: Prepare the prompt\n",
    "    user_prompt = (\n",
    "        f\"You are a Medical QnA AI. Use the references as contexts to answer the question.\\n\\n\"\n",
    "        f\"Select the single most likely diagnosis from the options.\\n\\n\"\n",
    "        f\"Respond ONLY with the disease name.\\n\\n\"\n",
    "        f\"Do NOT include reference labels in your answer.\\n\\n\"\n",
    "        f\"### References:\\n{context_block}\\n\\n\"\n",
    "        f\"### Question:\\n{query}\\n\\n\"\n",
    "        f\"### Options:\\n{options}\\n\\n\"\n",
    "        f\"### Final Answer:\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Compose messages and call LLM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Medical QnA AI that selects the most accurate answer.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Step 5: Return final result\n",
    "    return {\n",
    "        \"final_answer\": response.content.strip(),\n",
    "        \"references\": verified_references\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (deepseek)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/sajjadhadi_486_result.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"text\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references, ensure_ascii=False) # convert dict to string\n",
    "            df.loc[i, \"ds_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"ds\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/sajjadhadi_486_result.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (gpt)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/sajjadhadi_486_result.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"text\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references, ensure_ascii=False) # convert dict to string\n",
    "            df.loc[i, \"gpt_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"gpt\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/sajjadhadi_486_result.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1830ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis\n",
    "# Symptom2Disease (22 types, test = 212q)\n",
    "# top 1 reference + 1 llmself generated answer\n",
    "# https://huggingface.co/datasets/gretelai/symptom_to_diagnosis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b2803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier & Summarizer Func (MCQ)\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "## Verifier Agent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "verifier_prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\", \n",
    "        \"You are a medical verifier AI.\\n\"\n",
    "        \"Your role is to evaluate whether each reference is **relevant to the symptoms** described in the original question.\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"1. Carefully read the symptom description in the question.\\n\"\n",
    "        \"2. For each agent's reference, check if it describes symptoms that match or strongly relate to the question.\\n\"\n",
    "        \"3. Do NOT exclude a reference just because it refers to a different disease — as long as the symptoms are relevant, it should be kept.\\n\"\n",
    "        \"4. Exclude any references that do not meaningfully align with the symptom description, even if they are medically valid.\\n\"\n",
    "        \"5. Focus only on symptom relevance — diagnosis accuracy will be handled separately.\\n\\n\"\n",
    "        \"Output format:\\n\"\n",
    "        \"'selected_agents': [list of agent names with relevant references — do not modify the names]\\n\\n\"\n",
    "        \"DO NOT respond with anything else — no reasoning, no explanations, no formatting changes.\"\n",
    "    ),\n",
    "    (\"human\", \n",
    "     \"Original Question:\\n{question}\\n\\n\"\n",
    "     \"Retrieved Reference:\\n{ref}\")\n",
    "])\n",
    "\n",
    "\n",
    "verifier_chain = LLMChain(llm=llm, prompt=verifier_prompt)\n",
    "\n",
    "def verifier_agent(question: str, agent_reference: str):\n",
    "    verifier_result = verifier_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"ref\": agent_reference\n",
    "    })\n",
    "    print(f\"[Verifier response]:{verifier_result['text']}\")\n",
    "    \n",
    "    return verifier_result['text']\n",
    "\n",
    "## Summarizer Agent (MCQ)\n",
    "from typing import Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def summarizer_agent(verified_references: Dict[str, Dict[str, str]], query: str) -> Dict[str, Any]:\n",
    "    # Step 1: Extract all reference text across all sub-questions and sources\n",
    "    flattened_refs = []\n",
    "    for subq, sources in verified_references.items():\n",
    "        for source_name, content in sources.items():\n",
    "            flattened_refs.append(f\"[{source_name}] {content}\")\n",
    "\n",
    "    # Step 2: Combine all references into a block\n",
    "    context_block = \"\\n\\n\".join(flattened_refs)\n",
    "\n",
    "    options = \"drug reaction, allergy, chicken pox, diabetes, psoriasis, hypertension, cervical spondylosis, bronchial asthma, varicose veins, malaria, dengue, arthritis, impetigo, fungal infection, common cold, gastroesophageal reflux disease, urinary tract infection, typhoid, pneumonia, peptic ulcer disease, jaundice, migraine\"\n",
    "\n",
    "    # Step 3: Prepare the prompt\n",
    "    user_prompt = (\n",
    "        f\"You are a Medical QnA AI. Use the references as contexts to answer the question.\\n\\n\"\n",
    "        f\"Use ur internal knowledge if the contexts are irrelevant or wrong.\\n\\n\"\n",
    "        f\"Select the single most likely diagnosis from the options.\\n\\n\"\n",
    "        f\"Respond ONLY with the disease name.\\n\\n\"\n",
    "        f\"Do NOT include reference labels in your answer.\\n\\n\"\n",
    "        f\"### References:\\n{context_block}\\n\\n\"\n",
    "        f\"### Question:\\n{query}\\n\\n\"\n",
    "        f\"### Options:\\n{options}\\n\\n\"\n",
    "        f\"### Final Answer:\"\n",
    "    )\n",
    "\n",
    "    # Step 4: Compose messages and call LLM\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a Medical QnA AI that selects the most accurate answer.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Step 5: Return final result\n",
    "    return {\n",
    "        \"final_answer\": response.content.strip(),\n",
    "        \"references\": verified_references\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (DeepSeek)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/symp_diag_212_result.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"input\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"ds_reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references) # convert dict to string\n",
    "            df.loc[i, \"ds_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"ds\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/symp_diag_212_result.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfb18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verifier-Summarizer (GPT)\n",
    "import json\n",
    "df = pd.read_csv(\"../new_data/symp_diag_212_result.csv\")\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        query = df.loc[i, \"input\"]\n",
    "        if pd.notna(query):\n",
    "            retrieved_references = ast.literal_eval(df.loc[i, \"gpt_reference\"])\n",
    "            if isinstance(retrieved_references, dict):\n",
    "                # convert unicode to chi characters\n",
    "                decoded_value = {\n",
    "                    k: json.loads(f'\"{v}\"') if isinstance(v, str) else v\n",
    "                    for k, v in retrieved_references.items()\n",
    "                }\n",
    "            retrieved_references = decoded_value\n",
    "            print(retrieved_references)\n",
    "            verified_references = {}\n",
    "            \n",
    "            for question, agent_references in retrieved_references.items():\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Processing question: {question}\")\n",
    "                \n",
    "                # Run verifier agent for current question and its references\n",
    "                verifier_results = verifier_agent(question, agent_references)\n",
    "                \n",
    "                # Extract selected references based on verifier decision for current question\n",
    "                selected_references = {}\n",
    "                verifier_content = verifier_results.lower()\n",
    "                \n",
    "                # Simple parsing - look for agent names mentioned in the verifier result\n",
    "                for agent_name, reference in agent_references.items():\n",
    "                    if agent_name.lower() in verifier_content:\n",
    "                        selected_references[agent_name] = reference\n",
    "                \n",
    "                # Store selected references for this question\n",
    "                verified_references[question] = selected_references\n",
    "                \n",
    "                print(f\"Selected agents for this question: {list(selected_references.keys())}\")\n",
    "            \n",
    "            verified_references_str = json.dumps(verified_references) # convert dict to string\n",
    "            df.loc[i, \"gpt_ver_ref\"] = verified_references_str\n",
    "            print(\"[Verified references]: \", verified_references_str)\n",
    "            result = summarizer_agent(verified_references, query)\n",
    "            print(\"[Summarizer answer]: \", result[\"final_answer\"])\n",
    "            df.loc[i, \"gpt\"] = result[\"final_answer\"]\n",
    "            df.to_csv(\"../new_data/symp_diag_212_result.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
